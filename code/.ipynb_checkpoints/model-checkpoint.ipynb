{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/data-without-drift.zip\n",
      "../input/Y_test_proba.npy\n",
      "../input/train_clean_kalman.csv.zip\n",
      "../input/train_clean.csv\n",
      "../input/train_clean_kalman.csv\n",
      "../input/test_clean.csv\n",
      "../input/Y_train_proba.npy.zip\n",
      "../input/test_clean_kalman.csv.zip\n",
      "../input/test_clean_kalman.csv\n",
      "../input/liverpool-ion-switching.zip\n",
      "../input/sample_submission.csv\n",
      "../input/Y_train_proba.npy\n",
      "../input/train.csv\n",
      "../input/test.csv\n",
      "../input/Y_test_proba.npy.zip\n",
      "Reading Data Started...\n",
      "Reading and Normalizing Data Completed\n",
      "Creating Features\n",
      "Feature Engineering Started...\n",
      "Feature Engineering Completed...\n",
      "Training Wavenet model with 5 folds of GroupKFold Started...\n",
      "Our training dataset shape is (1000, 4000, 41)\n",
      "Our validation dataset shape is (250, 4000, 41)\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/180\n",
      "WARNING:tensorflow:From /home/dy/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "F1 Macro Score: 0.86261\n",
      "1000/1000 - 44s - loss: 0.4494 - accuracy: 0.8664 - val_loss: 0.3645 - val_accuracy: 0.9378\n",
      "Epoch 2/180\n",
      "F1 Macro Score: 0.92260\n",
      "1000/1000 - 12s - loss: 0.1346 - accuracy: 0.9633 - val_loss: 0.2004 - val_accuracy: 0.9598\n",
      "Epoch 3/180\n",
      "F1 Macro Score: 0.93281\n",
      "1000/1000 - 12s - loss: 0.1164 - accuracy: 0.9664 - val_loss: 0.1312 - val_accuracy: 0.9646\n",
      "Epoch 4/180\n",
      "F1 Macro Score: 0.93510\n",
      "1000/1000 - 12s - loss: 0.1103 - accuracy: 0.9670 - val_loss: 0.1123 - val_accuracy: 0.9658\n",
      "Epoch 5/180\n",
      "F1 Macro Score: 0.93601\n",
      "1000/1000 - 12s - loss: 0.1069 - accuracy: 0.9673 - val_loss: 0.1054 - val_accuracy: 0.9663\n",
      "Epoch 6/180\n",
      "F1 Macro Score: 0.93544\n",
      "1000/1000 - 12s - loss: 0.1052 - accuracy: 0.9675 - val_loss: 0.1076 - val_accuracy: 0.9657\n",
      "Epoch 7/180\n",
      "F1 Macro Score: 0.93749\n",
      "1000/1000 - 12s - loss: 0.1030 - accuracy: 0.9676 - val_loss: 0.1024 - val_accuracy: 0.9665\n",
      "Epoch 8/180\n",
      "F1 Macro Score: 0.93764\n",
      "1000/1000 - 12s - loss: 0.1020 - accuracy: 0.9676 - val_loss: 0.1000 - val_accuracy: 0.9667\n",
      "Epoch 9/180\n",
      "F1 Macro Score: 0.93830\n",
      "1000/1000 - 12s - loss: 0.0992 - accuracy: 0.9679 - val_loss: 0.0980 - val_accuracy: 0.9669\n",
      "Epoch 10/180\n",
      "F1 Macro Score: 0.93609\n",
      "1000/1000 - 12s - loss: 0.1025 - accuracy: 0.9673 - val_loss: 0.1027 - val_accuracy: 0.9661\n",
      "Epoch 11/180\n",
      "F1 Macro Score: 0.93755\n",
      "1000/1000 - 12s - loss: 0.0982 - accuracy: 0.9679 - val_loss: 0.0982 - val_accuracy: 0.9667\n",
      "Epoch 12/180\n",
      "F1 Macro Score: 0.93809\n",
      "1000/1000 - 12s - loss: 0.0961 - accuracy: 0.9680 - val_loss: 0.0965 - val_accuracy: 0.9670\n",
      "Epoch 13/180\n",
      "F1 Macro Score: 0.93589\n",
      "1000/1000 - 12s - loss: 0.0969 - accuracy: 0.9678 - val_loss: 0.1010 - val_accuracy: 0.9658\n",
      "Epoch 14/180\n",
      "F1 Macro Score: 0.93815\n",
      "1000/1000 - 12s - loss: 0.0952 - accuracy: 0.9680 - val_loss: 0.0950 - val_accuracy: 0.9670\n",
      "Epoch 15/180\n",
      "F1 Macro Score: 0.93761\n",
      "1000/1000 - 12s - loss: 0.0948 - accuracy: 0.9680 - val_loss: 0.0953 - val_accuracy: 0.9666\n",
      "Epoch 16/180\n",
      "F1 Macro Score: 0.93798\n",
      "1000/1000 - 12s - loss: 0.0929 - accuracy: 0.9681 - val_loss: 0.0932 - val_accuracy: 0.9670\n",
      "Epoch 17/180\n",
      "F1 Macro Score: 0.93812\n",
      "1000/1000 - 12s - loss: 0.0920 - accuracy: 0.9681 - val_loss: 0.0927 - val_accuracy: 0.9669\n",
      "Epoch 18/180\n",
      "F1 Macro Score: 0.93780\n",
      "1000/1000 - 12s - loss: 0.0911 - accuracy: 0.9682 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
      "Epoch 19/180\n",
      "F1 Macro Score: 0.93772\n",
      "1000/1000 - 12s - loss: 0.0924 - accuracy: 0.9680 - val_loss: 0.0927 - val_accuracy: 0.9670\n",
      "Epoch 20/180\n",
      "F1 Macro Score: 0.93829\n",
      "1000/1000 - 12s - loss: 0.0913 - accuracy: 0.9682 - val_loss: 0.0909 - val_accuracy: 0.9670\n",
      "Epoch 21/180\n",
      "F1 Macro Score: 0.93699\n",
      "1000/1000 - 12s - loss: 0.0895 - accuracy: 0.9682 - val_loss: 0.0941 - val_accuracy: 0.9661\n",
      "Epoch 22/180\n",
      "F1 Macro Score: 0.93740\n",
      "1000/1000 - 12s - loss: 0.0904 - accuracy: 0.9681 - val_loss: 0.0921 - val_accuracy: 0.9666\n",
      "Epoch 23/180\n",
      "F1 Macro Score: 0.93667\n",
      "1000/1000 - 12s - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.0927 - val_accuracy: 0.9663\n",
      "Epoch 24/180\n",
      "F1 Macro Score: 0.93719\n",
      "1000/1000 - 12s - loss: 0.0888 - accuracy: 0.9682 - val_loss: 0.0907 - val_accuracy: 0.9669\n",
      "Epoch 25/180\n",
      "F1 Macro Score: 0.93816\n",
      "1000/1000 - 12s - loss: 0.0893 - accuracy: 0.9682 - val_loss: 0.0897 - val_accuracy: 0.9669\n",
      "Epoch 26/180\n",
      "F1 Macro Score: 0.93785\n",
      "1000/1000 - 12s - loss: 0.0884 - accuracy: 0.9682 - val_loss: 0.0908 - val_accuracy: 0.9669\n",
      "Epoch 27/180\n",
      "F1 Macro Score: 0.93816\n",
      "1000/1000 - 12s - loss: 0.0868 - accuracy: 0.9684 - val_loss: 0.0888 - val_accuracy: 0.9670\n",
      "Epoch 28/180\n",
      "F1 Macro Score: 0.93659\n",
      "1000/1000 - 12s - loss: 0.0872 - accuracy: 0.9683 - val_loss: 0.0913 - val_accuracy: 0.9665\n",
      "Epoch 29/180\n",
      "F1 Macro Score: 0.93535\n",
      "1000/1000 - 12s - loss: 0.0871 - accuracy: 0.9683 - val_loss: 0.0928 - val_accuracy: 0.9664\n",
      "Epoch 30/180\n",
      "F1 Macro Score: 0.93608\n",
      "1000/1000 - 12s - loss: 0.0898 - accuracy: 0.9679 - val_loss: 0.0934 - val_accuracy: 0.9660\n",
      "Epoch 31/180\n",
      "F1 Macro Score: 0.93798\n",
      "1000/1000 - 12s - loss: 0.0855 - accuracy: 0.9686 - val_loss: 0.0885 - val_accuracy: 0.9670\n",
      "Epoch 32/180\n",
      "F1 Macro Score: 0.93841\n",
      "1000/1000 - 12s - loss: 0.0848 - accuracy: 0.9687 - val_loss: 0.0877 - val_accuracy: 0.9671\n",
      "Epoch 33/180\n",
      "F1 Macro Score: 0.93835\n",
      "1000/1000 - 12s - loss: 0.0845 - accuracy: 0.9687 - val_loss: 0.0875 - val_accuracy: 0.9671\n",
      "Epoch 34/180\n",
      "F1 Macro Score: 0.93813\n",
      "1000/1000 - 12s - loss: 0.0845 - accuracy: 0.9687 - val_loss: 0.0877 - val_accuracy: 0.9670\n",
      "Epoch 35/180\n",
      "F1 Macro Score: 0.93834\n",
      "1000/1000 - 12s - loss: 0.0845 - accuracy: 0.9687 - val_loss: 0.0874 - val_accuracy: 0.9671\n",
      "Epoch 36/180\n",
      "F1 Macro Score: 0.93803\n",
      "1000/1000 - 12s - loss: 0.0840 - accuracy: 0.9687 - val_loss: 0.0870 - val_accuracy: 0.9672\n",
      "Epoch 37/180\n",
      "F1 Macro Score: 0.93823\n",
      "1000/1000 - 12s - loss: 0.0842 - accuracy: 0.9688 - val_loss: 0.0867 - val_accuracy: 0.9672\n",
      "Epoch 38/180\n",
      "F1 Macro Score: 0.93766\n",
      "1000/1000 - 12s - loss: 0.0843 - accuracy: 0.9687 - val_loss: 0.0873 - val_accuracy: 0.9671\n",
      "Epoch 39/180\n",
      "F1 Macro Score: 0.93744\n",
      "1000/1000 - 12s - loss: 0.0838 - accuracy: 0.9688 - val_loss: 0.0881 - val_accuracy: 0.9671\n",
      "Epoch 40/180\n",
      "F1 Macro Score: 0.93807\n",
      "1000/1000 - 12s - loss: 0.0836 - accuracy: 0.9688 - val_loss: 0.0866 - val_accuracy: 0.9673\n",
      "Epoch 41/180\n",
      "F1 Macro Score: 0.93887\n",
      "1000/1000 - 12s - loss: 0.0832 - accuracy: 0.9688 - val_loss: 0.0863 - val_accuracy: 0.9673\n",
      "Epoch 42/180\n",
      "F1 Macro Score: 0.93886\n",
      "1000/1000 - 12s - loss: 0.0831 - accuracy: 0.9690 - val_loss: 0.0862 - val_accuracy: 0.9674\n",
      "Epoch 43/180\n",
      "F1 Macro Score: 0.93804\n",
      "1000/1000 - 12s - loss: 0.0832 - accuracy: 0.9689 - val_loss: 0.0868 - val_accuracy: 0.9672\n",
      "Epoch 44/180\n",
      "F1 Macro Score: 0.93897\n",
      "1000/1000 - 12s - loss: 0.0827 - accuracy: 0.9691 - val_loss: 0.0859 - val_accuracy: 0.9675\n",
      "Epoch 45/180\n",
      "F1 Macro Score: 0.93875\n",
      "1000/1000 - 12s - loss: 0.0831 - accuracy: 0.9690 - val_loss: 0.0859 - val_accuracy: 0.9675\n",
      "Epoch 46/180\n",
      "F1 Macro Score: 0.93896\n",
      "1000/1000 - 12s - loss: 0.0827 - accuracy: 0.9691 - val_loss: 0.0855 - val_accuracy: 0.9676\n",
      "Epoch 47/180\n",
      "F1 Macro Score: 0.93943\n",
      "1000/1000 - 12s - loss: 0.0826 - accuracy: 0.9692 - val_loss: 0.0856 - val_accuracy: 0.9677\n",
      "Epoch 48/180\n",
      "F1 Macro Score: 0.93937\n",
      "1000/1000 - 12s - loss: 0.0821 - accuracy: 0.9693 - val_loss: 0.0854 - val_accuracy: 0.9676\n",
      "Epoch 49/180\n",
      "F1 Macro Score: 0.93947\n",
      "1000/1000 - 12s - loss: 0.0819 - accuracy: 0.9693 - val_loss: 0.0850 - val_accuracy: 0.9679\n",
      "Epoch 50/180\n",
      "F1 Macro Score: 0.93925\n",
      "1000/1000 - 12s - loss: 0.0813 - accuracy: 0.9696 - val_loss: 0.0854 - val_accuracy: 0.9678\n",
      "Epoch 51/180\n",
      "F1 Macro Score: 0.94021\n",
      "1000/1000 - 12s - loss: 0.0811 - accuracy: 0.9696 - val_loss: 0.0841 - val_accuracy: 0.9682\n",
      "Epoch 52/180\n",
      "F1 Macro Score: 0.93966\n",
      "1000/1000 - 12s - loss: 0.0808 - accuracy: 0.9698 - val_loss: 0.0843 - val_accuracy: 0.9681\n",
      "Epoch 53/180\n",
      "F1 Macro Score: 0.94061\n",
      "1000/1000 - 12s - loss: 0.0805 - accuracy: 0.9699 - val_loss: 0.0837 - val_accuracy: 0.9683\n",
      "Epoch 54/180\n",
      "F1 Macro Score: 0.94032\n",
      "1000/1000 - 12s - loss: 0.0806 - accuracy: 0.9698 - val_loss: 0.0837 - val_accuracy: 0.9682\n",
      "Epoch 55/180\n",
      "F1 Macro Score: 0.94060\n",
      "1000/1000 - 12s - loss: 0.0807 - accuracy: 0.9699 - val_loss: 0.0837 - val_accuracy: 0.9684\n",
      "Epoch 56/180\n",
      "F1 Macro Score: 0.93993\n",
      "1000/1000 - 12s - loss: 0.0805 - accuracy: 0.9698 - val_loss: 0.0839 - val_accuracy: 0.9681\n",
      "Epoch 57/180\n",
      "F1 Macro Score: 0.94003\n",
      "1000/1000 - 12s - loss: 0.0800 - accuracy: 0.9700 - val_loss: 0.0841 - val_accuracy: 0.9682\n",
      "Epoch 58/180\n",
      "F1 Macro Score: 0.94062\n",
      "1000/1000 - 12s - loss: 0.0795 - accuracy: 0.9701 - val_loss: 0.0836 - val_accuracy: 0.9683\n",
      "Epoch 59/180\n",
      "F1 Macro Score: 0.94067\n",
      "1000/1000 - 12s - loss: 0.0800 - accuracy: 0.9700 - val_loss: 0.0833 - val_accuracy: 0.9684\n",
      "Epoch 60/180\n",
      "F1 Macro Score: 0.93981\n",
      "1000/1000 - 12s - loss: 0.0800 - accuracy: 0.9701 - val_loss: 0.0837 - val_accuracy: 0.9683\n",
      "Epoch 61/180\n",
      "F1 Macro Score: 0.94042\n",
      "1000/1000 - 12s - loss: 0.0797 - accuracy: 0.9701 - val_loss: 0.0834 - val_accuracy: 0.9684\n",
      "Epoch 62/180\n",
      "F1 Macro Score: 0.94043\n",
      "1000/1000 - 12s - loss: 0.0796 - accuracy: 0.9701 - val_loss: 0.0828 - val_accuracy: 0.9684\n",
      "Epoch 63/180\n",
      "F1 Macro Score: 0.94019\n",
      "1000/1000 - 12s - loss: 0.0794 - accuracy: 0.9702 - val_loss: 0.0835 - val_accuracy: 0.9683\n",
      "Epoch 64/180\n",
      "F1 Macro Score: 0.94045\n",
      "1000/1000 - 12s - loss: 0.0796 - accuracy: 0.9701 - val_loss: 0.0828 - val_accuracy: 0.9684\n",
      "Epoch 65/180\n",
      "F1 Macro Score: 0.94058\n",
      "1000/1000 - 12s - loss: 0.0792 - accuracy: 0.9703 - val_loss: 0.0830 - val_accuracy: 0.9684\n",
      "Epoch 66/180\n",
      "F1 Macro Score: 0.94070\n",
      "1000/1000 - 12s - loss: 0.0794 - accuracy: 0.9702 - val_loss: 0.0828 - val_accuracy: 0.9685\n",
      "Epoch 67/180\n",
      "F1 Macro Score: 0.94088\n",
      "1000/1000 - 12s - loss: 0.0793 - accuracy: 0.9702 - val_loss: 0.0825 - val_accuracy: 0.9685\n",
      "Epoch 68/180\n",
      "F1 Macro Score: 0.94076\n",
      "1000/1000 - 12s - loss: 0.0790 - accuracy: 0.9703 - val_loss: 0.0825 - val_accuracy: 0.9685\n",
      "Epoch 69/180\n",
      "F1 Macro Score: 0.94076\n",
      "1000/1000 - 12s - loss: 0.0792 - accuracy: 0.9703 - val_loss: 0.0830 - val_accuracy: 0.9686\n",
      "Epoch 70/180\n",
      "F1 Macro Score: 0.94010\n",
      "1000/1000 - 12s - loss: 0.0789 - accuracy: 0.9703 - val_loss: 0.0838 - val_accuracy: 0.9683\n",
      "Epoch 71/180\n",
      "F1 Macro Score: 0.94088\n",
      "1000/1000 - 12s - loss: 0.0792 - accuracy: 0.9702 - val_loss: 0.0825 - val_accuracy: 0.9686\n",
      "Epoch 72/180\n",
      "F1 Macro Score: 0.94070\n",
      "1000/1000 - 12s - loss: 0.0787 - accuracy: 0.9704 - val_loss: 0.0826 - val_accuracy: 0.9686\n",
      "Epoch 73/180\n",
      "F1 Macro Score: 0.94061\n",
      "1000/1000 - 12s - loss: 0.0788 - accuracy: 0.9703 - val_loss: 0.0826 - val_accuracy: 0.9685\n",
      "Epoch 74/180\n",
      "F1 Macro Score: 0.94065\n",
      "1000/1000 - 12s - loss: 0.0789 - accuracy: 0.9703 - val_loss: 0.0824 - val_accuracy: 0.9686\n",
      "Epoch 75/180\n",
      "F1 Macro Score: 0.94112\n",
      "1000/1000 - 12s - loss: 0.0788 - accuracy: 0.9703 - val_loss: 0.0822 - val_accuracy: 0.9687\n",
      "Epoch 76/180\n",
      "F1 Macro Score: 0.94021\n",
      "1000/1000 - 12s - loss: 0.0787 - accuracy: 0.9703 - val_loss: 0.0830 - val_accuracy: 0.9685\n",
      "Epoch 77/180\n",
      "F1 Macro Score: 0.94100\n",
      "1000/1000 - 12s - loss: 0.0787 - accuracy: 0.9704 - val_loss: 0.0824 - val_accuracy: 0.9687\n",
      "Epoch 78/180\n",
      "F1 Macro Score: 0.94101\n",
      "1000/1000 - 12s - loss: 0.0791 - accuracy: 0.9703 - val_loss: 0.0825 - val_accuracy: 0.9686\n",
      "Epoch 79/180\n",
      "F1 Macro Score: 0.94107\n",
      "1000/1000 - 12s - loss: 0.0784 - accuracy: 0.9704 - val_loss: 0.0821 - val_accuracy: 0.9687\n",
      "Epoch 80/180\n",
      "F1 Macro Score: 0.94103\n",
      "1000/1000 - 12s - loss: 0.0785 - accuracy: 0.9704 - val_loss: 0.0822 - val_accuracy: 0.9687\n",
      "Epoch 81/180\n",
      "F1 Macro Score: 0.94079\n",
      "1000/1000 - 12s - loss: 0.0786 - accuracy: 0.9704 - val_loss: 0.0822 - val_accuracy: 0.9686\n",
      "Epoch 82/180\n",
      "F1 Macro Score: 0.94088\n",
      "1000/1000 - 12s - loss: 0.0786 - accuracy: 0.9704 - val_loss: 0.0823 - val_accuracy: 0.9686\n",
      "Epoch 83/180\n",
      "F1 Macro Score: 0.94088\n",
      "1000/1000 - 12s - loss: 0.0783 - accuracy: 0.9704 - val_loss: 0.0820 - val_accuracy: 0.9686\n",
      "Epoch 84/180\n",
      "F1 Macro Score: 0.94022\n",
      "1000/1000 - 12s - loss: 0.0783 - accuracy: 0.9704 - val_loss: 0.0826 - val_accuracy: 0.9685\n",
      "Epoch 85/180\n",
      "F1 Macro Score: 0.94082\n",
      "1000/1000 - 12s - loss: 0.0785 - accuracy: 0.9704 - val_loss: 0.0821 - val_accuracy: 0.9686\n",
      "Epoch 86/180\n",
      "F1 Macro Score: 0.94101\n",
      "1000/1000 - 12s - loss: 0.0783 - accuracy: 0.9704 - val_loss: 0.0821 - val_accuracy: 0.9687\n",
      "Epoch 87/180\n",
      "F1 Macro Score: 0.94100\n",
      "1000/1000 - 12s - loss: 0.0781 - accuracy: 0.9705 - val_loss: 0.0819 - val_accuracy: 0.9687\n",
      "Epoch 88/180\n",
      "F1 Macro Score: 0.94094\n",
      "1000/1000 - 12s - loss: 0.0783 - accuracy: 0.9704 - val_loss: 0.0821 - val_accuracy: 0.9687\n",
      "Epoch 89/180\n",
      "F1 Macro Score: 0.94102\n",
      "1000/1000 - 12s - loss: 0.0782 - accuracy: 0.9705 - val_loss: 0.0822 - val_accuracy: 0.9686\n",
      "Epoch 90/180\n",
      "F1 Macro Score: 0.94106\n",
      "1000/1000 - 12s - loss: 0.0781 - accuracy: 0.9705 - val_loss: 0.0821 - val_accuracy: 0.9687\n",
      "Epoch 91/180\n",
      "F1 Macro Score: 0.94121\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 92/180\n",
      "F1 Macro Score: 0.94125\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9705 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 93/180\n",
      "F1 Macro Score: 0.94122\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 94/180\n",
      "F1 Macro Score: 0.94116\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 95/180\n",
      "F1 Macro Score: 0.94108\n",
      "1000/1000 - 12s - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 96/180\n",
      "F1 Macro Score: 0.94113\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 97/180\n",
      "F1 Macro Score: 0.94111\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 98/180\n",
      "F1 Macro Score: 0.94111\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 99/180\n",
      "F1 Macro Score: 0.94112\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 100/180\n",
      "F1 Macro Score: 0.94118\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 101/180\n",
      "F1 Macro Score: 0.94097\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 102/180\n",
      "F1 Macro Score: 0.94110\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 103/180\n",
      "F1 Macro Score: 0.94106\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 104/180\n",
      "F1 Macro Score: 0.94098\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 105/180\n",
      "F1 Macro Score: 0.94101\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9705 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 106/180\n",
      "F1 Macro Score: 0.94122\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 107/180\n",
      "F1 Macro Score: 0.94111\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 108/180\n",
      "F1 Macro Score: 0.94100\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 109/180\n",
      "F1 Macro Score: 0.94119\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 110/180\n",
      "F1 Macro Score: 0.94097\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 111/180\n",
      "F1 Macro Score: 0.94116\n",
      "1000/1000 - 12s - loss: 0.0774 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 112/180\n",
      "F1 Macro Score: 0.94106\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 113/180\n",
      "F1 Macro Score: 0.94107\n",
      "1000/1000 - 12s - loss: 0.0782 - accuracy: 0.9705 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 114/180\n",
      "F1 Macro Score: 0.94099\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 115/180\n",
      "F1 Macro Score: 0.94099\n",
      "1000/1000 - 12s - loss: 0.0779 - accuracy: 0.9705 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 116/180\n",
      "F1 Macro Score: 0.94105\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 117/180\n",
      "F1 Macro Score: 0.94125\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 118/180\n",
      "F1 Macro Score: 0.94123\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 119/180\n",
      "F1 Macro Score: 0.94100\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 120/180\n",
      "F1 Macro Score: 0.94117\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9705 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 121/180\n",
      "F1 Macro Score: 0.94097\n",
      "1000/1000 - 12s - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 122/180\n",
      "F1 Macro Score: 0.94112\n",
      "1000/1000 - 12s - loss: 0.0779 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 123/180\n",
      "F1 Macro Score: 0.94111\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 124/180\n",
      "F1 Macro Score: 0.94118\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 125/180\n",
      "F1 Macro Score: 0.94117\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 126/180\n",
      "F1 Macro Score: 0.94108\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9705 - val_loss: 0.0818 - val_accuracy: 0.9687\n",
      "Epoch 127/180\n",
      "F1 Macro Score: 0.94118\n",
      "1000/1000 - 12s - loss: 0.0781 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 128/180\n",
      "F1 Macro Score: 0.94115\n",
      "1000/1000 - 12s - loss: 0.0777 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 129/180\n",
      "F1 Macro Score: 0.94117\n",
      "1000/1000 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 130/180\n",
      "F1 Macro Score: 0.94114\n",
      "1000/1000 - 12s - loss: 0.0775 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 131/180\n",
      "F1 Macro Score: 0.94119\n",
      "1000/1000 - 12s - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 132/180\n",
      "F1 Macro Score: 0.94107\n",
      "1000/1000 - 12s - loss: 0.0775 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 133/180\n",
      "F1 Macro Score: 0.94111\n",
      "1000/1000 - 12s - loss: 0.0774 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 134/180\n",
      "F1 Macro Score: 0.94113\n",
      "1000/1000 - 12s - loss: 0.0775 - accuracy: 0.9706 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 135/180\n",
      "F1 Macro Score: 0.94112\n",
      "1000/1000 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 136/180\n",
      "F1 Macro Score: 0.94119\n",
      "1000/1000 - 12s - loss: 0.0779 - accuracy: 0.9705 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 137/180\n",
      "Best epoch 117 and second best epoch 92 selected\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_start\u001b[0;34m(self, model, callbacks, use_samples, verbose, mode)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_successful_loop_finish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-650b885607d5>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-650b885607d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training completed...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m \u001b[0mrun_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-650b885607d5>\u001b[0m in \u001b[0;36mrun_everything\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training Wavenet model with {SPLITS} folds of GroupKFold Started...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0mrun_cv_model_by_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPLITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNNBATCHSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training completed...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-650b885607d5>\u001b[0m in \u001b[0;36mrun_cv_model_by_batch\u001b[0;34m(train, test, splits, batch_col, feats, sample_submission, nn_epochs, nn_batch_size)\u001b[0m\n\u001b[1;32m    333\u001b[0m                   \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb_lr_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMacroF1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# adding custom evaluation metric for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                   validation_data = (valid_x,valid_y))\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_start\u001b[0;34m(self, model, callbacks, use_samples, verbose, mode)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m       \u001b[0;31m# End of all epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_end_hook\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;34m\"\"\"Helper function for on_{train|test|predict}_end methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \"\"\"\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-650b885607d5>\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswa_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mval_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Thanks to https://www.kaggle.com/siavrez/wavenet-keras and Sergey Bryansky\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "import tensorflow_addons as tfa\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# configurations and main hyperparammeters\n",
    "EPOCHS = 180\n",
    "NNBATCHSIZE = 16\n",
    "GROUP_BATCH_SIZE = 4000\n",
    "SEED = 321\n",
    "LR = 0.001\n",
    "SPLITS = 5\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# read data\n",
    "def read_data():\n",
    "    train = pd.read_csv('../input/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\n",
    "    test  = pd.read_csv('../input/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\n",
    "    sub  = pd.read_csv('../input/sample_submission.csv', dtype={'time': np.float32})\n",
    "    \n",
    "    Y_train_proba = np.load(\"../input/Y_train_proba.npy\")\n",
    "    Y_test_proba = np.load(\"../input/Y_test_proba.npy\")\n",
    "    \n",
    "    for i in range(11):\n",
    "        train[f\"proba_{i}\"] = Y_train_proba[:, i]\n",
    "        test[f\"proba_{i}\"] = Y_test_proba[:, i]\n",
    "        \n",
    "       \n",
    "    Y_train_proba_lgb = np.load(\"oof_train/oof_train_lgb940_5fold.npy\")\n",
    "    Y_test_proba_lgb = np.load(\"oof_test/oof_test_lgb940_5fold.npy\")\n",
    "    \n",
    "    \n",
    "    train['lgb940'] = Y_train_proba_lgb\n",
    "    test['lgb940'] = Y_test_proba_lgb\n",
    "    \n",
    "  \n",
    "\n",
    "#     Y_train_proba_lgb = np.load(\"oof_train/oof_train_lgbmlp.npy\")\n",
    "#     Y_test_proba_lgb = np.load(\"oof_test/oof_test_lgbmlp.npy\")\n",
    "    \n",
    "#     for i in range(11):\n",
    "#         train[f\"lgb_proba_{i}\"] = Y_train_proba_lgb[:, i]\n",
    "#         test[f\"lgb_proba_{i}\"] = Y_test_proba_lgb[:, i]\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    Y_train_proba = np.load(\"oof_train/oof_train_seq2seq_lb940.npy\")\n",
    "    Y_test_proba = np.load(\"oof_test/oof_test_seq2seq_lb940.npy\")\n",
    "    \n",
    "    for i in range(11):\n",
    "        train[f\"seq2seq_proba_{i}\"] = Y_train_proba[:, i]\n",
    "        test[f\"seq2seq_proba_{i}\"] = Y_test_proba[:, i]\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "#     Y_train_proba = np.load(\"oof_train/oof_train_seq2seq_lb942.npy\")\n",
    "#     Y_test_proba = np.load(\"oof_test/oof_test_seq2seq_lb942.npy\")\n",
    "    \n",
    "#     for i in range(11):\n",
    "#         train[f\"seq2seq_proba_{i}\"] = Y_train_proba[:, i]\n",
    "#         test[f\"seq2seq_proba_{i}\"] = Y_test_proba[:, i]      \n",
    "        \n",
    "        \n",
    "\n",
    "    return train, test, sub\n",
    "\n",
    "# create batches of 4000 observations\n",
    "def batching(df, batch_size):\n",
    "    df['group'] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n",
    "    df['group'] = df['group'].astype(np.uint16)\n",
    "    return df\n",
    "\n",
    "# normalize the data (standard scaler). We can also try other scalers for a better score!\n",
    "def normalize(train, test):\n",
    "    features = [col for col in train.columns if col not in ['index', 'group', 'open_channels', 'time']]\n",
    "    for f in features:\n",
    "        if 'prob' in f:\n",
    "            continue\n",
    "\n",
    "        train_input_mean = train[f].mean()\n",
    "        train_input_sigma = train[f].std()\n",
    "        train[f] = (train[f]- train_input_mean) / train_input_sigma\n",
    "        test[f] = (test[f] - train_input_mean) / train_input_sigma\n",
    "    return train, test\n",
    "\n",
    "# get lead and lags features\n",
    "def lag_with_pct_change(df, windows):\n",
    "    for window in windows:    \n",
    "        df['signal_shift_pos_' + str(window)] = df.groupby('group')['signal'].shift(window).fillna(0)\n",
    "        df['signal_shift_neg_' + str(window)] = df.groupby('group')['signal'].shift(-1 * window).fillna(0)\n",
    "    return df\n",
    "\n",
    "# main module to run feature engineering. Here you may want to try and add other features and check if your score imporves :).\n",
    "def run_feat_engineering(df, batch_size):\n",
    "    # create batches\n",
    "    df = batching(df, batch_size = batch_size)\n",
    "    # create leads and lags (1, 2, 3 making them 6 features)\n",
    "    df = lag_with_pct_change(df, [1, 2, 3])\n",
    "    # create signal ** 2 (this is the new feature)\n",
    "    # df['signal_2'] = df['signal'] ** 2\n",
    "    # df['signal_value_count'] = df['signal'].map(df['signal'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# fillna with the mean and select features for training\n",
    "def feature_selection(train, test):\n",
    "    features = [col for col in train.columns if col not in ['index', 'group', 'open_channels', 'time']]\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "    test = test.replace([np.inf, -np.inf], np.nan)\n",
    "    for feature in features:\n",
    "        feature_mean = pd.concat([train[feature], test[feature]], axis = 0).mean()\n",
    "        train[feature] = train[feature].fillna(feature_mean)\n",
    "        test[feature] = test[feature].fillna(feature_mean)\n",
    "    return train, test, features\n",
    "\n",
    "import  tensorflow.keras.layers  as L\n",
    "\n",
    "\n",
    "# model function (very important, you can try different arquitectures to get a better score. I believe that top public leaderboard is a 1D Conv + RNN style)\n",
    "def Classifier(shape_):\n",
    "    \n",
    "    def cbr(x, out_layer, kernel, stride, dilation):\n",
    "        x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        return x\n",
    "    \n",
    "    def wave_block(x, filters, kernel_size, n):\n",
    "        dilation_rates = [2**i for i in range(n)]\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = x\n",
    "        for dilation_rate in dilation_rates:\n",
    "            tanh_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same', \n",
    "                              activation = 'tanh', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            sigm_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same',\n",
    "                              activation = 'sigmoid', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            x = Multiply()([tanh_out, sigm_out])\n",
    "            x = Conv1D(filters = filters,\n",
    "                       kernel_size = 1,\n",
    "                       padding = 'same')(x)\n",
    "            res_x = Add()([res_x, x])\n",
    "        return res_x\n",
    "    \n",
    "    inp = Input(shape = (shape_))\n",
    "    x = cbr(inp, 64, 7, 1, 1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 16, 3, 12)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 32, 3, 8)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = L.concatenate([L.GlobalMaxPooling1D()(x),L.GlobalAveragePooling1D()(x)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    x2 = cbr(inp, 64, 7, 1, 1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = wave_block(x2, 8, 3, 12)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = wave_block(x2, 16, 3, 8)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = wave_block(x2, 32, 3, 4)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    \n",
    "\n",
    "\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(11, activation = 'softmax', name = 'out')(x)\n",
    "    \n",
    "    model = models.Model(inputs = inp, outputs = out)\n",
    "    \n",
    "    opt = Adam(lr = LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(loss = losses.CategoricalCrossentropy(), optimizer = opt, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# function that decrease the learning as epochs increase (i also change this part of the code)\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 30:\n",
    "        lr = LR\n",
    "    elif epoch < 40:\n",
    "        lr = LR / 3\n",
    "    elif epoch < 50:\n",
    "        lr = LR / 5\n",
    "    elif epoch < 60:\n",
    "        lr = LR / 7\n",
    "    elif epoch < 70:\n",
    "        lr = LR / 9\n",
    "    elif epoch < 80:\n",
    "        lr = LR / 11\n",
    "    elif epoch < 90:\n",
    "        lr = LR / 13\n",
    "    else:\n",
    "        lr = LR / 100\n",
    "    return lr\n",
    "\n",
    "# class to get macro f1 score. This is not entirely necessary but it's fun to check f1 score of each epoch (be carefull, if you use this function early stopping callback will not work)\n",
    "class MacroF1(Callback):\n",
    "    def __init__(self, model, inputs, targets,model_name):\n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis = 2).reshape(-1)\n",
    "        self.model_name = model_name\n",
    "        self.f1 = []\n",
    "        self.model_weights = []\n",
    "        self.f1_init = -1\n",
    "        \n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis = 2).reshape(-1)\n",
    "        score = f1_score(self.targets, pred, average = 'macro')\n",
    "        print(f'F1 Macro Score: {score:.5f}')\n",
    "        self.f1.append(score)\n",
    "        self.model_weights.append(self.model.get_weights())\n",
    "        \n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"\n",
    "        Weighted average of weights from two best epochs\n",
    "\n",
    "        \"\"\"\n",
    "        f1_selected = np.argsort(self.f1)[-2:]\n",
    "        print(f'Best epoch {f1_selected[1]+1} and second best epoch {f1_selected[0]+1} selected')\n",
    "        swa_weights = [x * 0.3 + y * 0.7 for x, y in zip(self.model_weights[f1_selected[0]], self.model_weights[f1_selected[1]])]\n",
    "        self.model.set_weights(swa_weights)\n",
    "        \n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis = 2).reshape(-1)\n",
    "        val_pred  = f1_score(self.targets, pred, average = 'macro')\n",
    "        \n",
    "\n",
    "        \n",
    "        print('SWD Model F1 - {:.5f}'.format(val_pred))\n",
    "        if val_pred>self.f1_init:\n",
    "            self.rho_init = val_pred\n",
    "            print('Save SWD Weights')\n",
    "            self.model.save_weights(self.model_name)\n",
    "        del self.f1, self.model_weights, swa_weights\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "# main function to perfrom groupkfold cross validation (we have 1000 vectores of 4000 rows and 8 features (columns)). Going to make 5 groups with this subgroups.\n",
    "def run_cv_model_by_batch(train, test, splits, batch_col, feats, sample_submission, nn_epochs, nn_batch_size):\n",
    "    \n",
    "    seed_everything(SEED)\n",
    "    K.clear_session()\n",
    "    config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    oof_ = np.zeros((len(train), 11)) # build out of folds matrix with 11 columns, they represent our target variables classes (from 0 to 10)\n",
    "    preds_ = np.zeros((len(test), 11))\n",
    "    target = ['open_channels']\n",
    "    group = train['group']\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    splits = [x for x in kf.split(train, train[target], group)]\n",
    "\n",
    "    new_splits = []\n",
    "    for sp in splits:\n",
    "        new_split = []\n",
    "        new_split.append(np.unique(group[sp[0]]))\n",
    "        new_split.append(np.unique(group[sp[1]]))\n",
    "        new_split.append(sp[1])    \n",
    "        new_splits.append(new_split)\n",
    "    # pivot target columns to transform the net to a multiclass classification estructure (you can also leave it in 1 vector with sparsecategoricalcrossentropy loss function)\n",
    "    tr = pd.concat([pd.get_dummies(train.open_channels), train[['group']]], axis=1)\n",
    "\n",
    "    tr.columns = ['target_'+str(i) for i in range(11)] + ['group']\n",
    "    target_cols = ['target_'+str(i) for i in range(11)]\n",
    "    train_tr = np.array(list(tr.groupby('group').apply(lambda x: x[target_cols].values))).astype(np.float32)\n",
    "    train = np.array(list(train.groupby('group').apply(lambda x: x[feats].values)))\n",
    "    test = np.array(list(test.groupby('group').apply(lambda x: x[feats].values)))\n",
    "\n",
    "    for n_fold, (tr_idx, val_idx, val_orig_idx) in enumerate(new_splits[0:], start=0):\n",
    "        train_x, train_y = train[tr_idx], train_tr[tr_idx]\n",
    "        valid_x, valid_y = train[val_idx], train_tr[val_idx]\n",
    "        print(f'Our training dataset shape is {train_x.shape}')\n",
    "        print(f'Our validation dataset shape is {valid_x.shape}')\n",
    "        model_path = 'keras_model'\n",
    "        \n",
    "        model_weight = f'{model_path}/bert_fold{n_fold}.h5'\n",
    "\n",
    "\n",
    "        gc.collect()\n",
    "        shape_ = (None, train_x.shape[2]) # input is going to be the number of feature we are using (dimension 2 of 0, 1, 2)\n",
    "        model = Classifier(shape_)\n",
    "        # using our lr_schedule function\n",
    "        cb_lr_schedule = LearningRateScheduler(lr_schedule)\n",
    "        model.fit(train_x,train_y,\n",
    "                  epochs = nn_epochs,\n",
    "                  callbacks = [cb_lr_schedule, MacroF1(model, valid_x, valid_y,model_weight)], # adding custom evaluation metric for each epoch\n",
    "                  batch_size = nn_batch_size,verbose = 2,\n",
    "                  validation_data = (valid_x,valid_y))\n",
    "        \n",
    "        model.load_weights(model_weight)\n",
    "        \n",
    "        preds_f = model.predict(valid_x)\n",
    "        f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  np.argmax(preds_f, axis=2).reshape(-1), average = 'macro') # need to get the class with the biggest probability\n",
    "        print(f'Training fold {n_fold + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n",
    "        preds_f = preds_f.reshape(-1, preds_f.shape[-1])\n",
    "        oof_[val_orig_idx,:] += preds_f\n",
    "        te_preds = model.predict(test)\n",
    "        te_preds = te_preds.reshape(-1, te_preds.shape[-1])           \n",
    "        preds_ += te_preds / SPLITS\n",
    "    # calculate the oof macro f1_score\n",
    "    f1_score_ = f1_score(np.argmax(train_tr, axis = 2).reshape(-1),  np.argmax(oof_, axis = 1), average = 'macro') # axis 2 for the 3 Dimension array and axis 1 for the 2 Domension Array (extracting the best class)\n",
    "    print(f'Training completed. oof macro f1 score : {f1_score_:1.5f}')\n",
    "    sample_submission['open_channels'] = np.argmax(preds_, axis = 1).astype(int)\n",
    "    sample_submission.to_csv('submission_wavenet.csv', index=False, float_format='%.4f')\n",
    "\n",
    "    np.save(\"oof_train_944.npy\",oof_)\n",
    "    np.save(\"oof_test_944.npy\",preds_)\n",
    "    \n",
    "# this function run our entire program\n",
    "def run_everything():\n",
    "    \n",
    "    print('Reading Data Started...')\n",
    "    train, test, sample_submission = read_data()\n",
    "    train, test = normalize(train, test)\n",
    "    print('Reading and Normalizing Data Completed')\n",
    "        \n",
    "    print('Creating Features')\n",
    "    print('Feature Engineering Started...')\n",
    "    train = run_feat_engineering(train, batch_size = GROUP_BATCH_SIZE)\n",
    "    test = run_feat_engineering(test, batch_size = GROUP_BATCH_SIZE)\n",
    "    train, test, features = feature_selection(train, test)\n",
    "    print('Feature Engineering Completed...')\n",
    "        \n",
    "   \n",
    "    print(f'Training Wavenet model with {SPLITS} folds of GroupKFold Started...')\n",
    "    run_cv_model_by_batch(train, test, SPLITS, 'group', features, sample_submission, EPOCHS, NNBATCHSIZE)\n",
    "    print('Training completed...')\n",
    "        \n",
    "run_everything()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
