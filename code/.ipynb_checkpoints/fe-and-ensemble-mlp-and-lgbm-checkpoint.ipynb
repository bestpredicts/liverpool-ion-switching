{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, plot_confusion_matrix\n",
    "from keras.models import Model\n",
    "import keras.layers as L\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Thanks to https://www.kaggle.com/cdeotte/data-without-drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels\n",
       "0  0.0001 -2.7600              0\n",
       "1  0.0002 -2.8557              0\n",
       "2  0.0003 -2.4074              0\n",
       "3  0.0004 -3.1404              0\n",
       "4  0.0005 -3.1525              0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "data = pd.read_csv('../input/train_clean.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Add to signal several other signals: gradients, rolling mean, std, low/high pass filters...\n",
    "\n",
    "FE is the same as this notebook https://www.kaggle.com/martxelo/fe-and-simple-mlp with corrections in filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradients(s, n_grads=4):\n",
    "    '''\n",
    "    Calculate gradients for a pandas series. Returns the same number of samples\n",
    "    '''\n",
    "    grads = pd.DataFrame()\n",
    "    \n",
    "    g = s.values\n",
    "    for i in range(n_grads):\n",
    "        g = np.gradient(g)\n",
    "        grads['grad_' + str(i+1)] = g\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_low_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies low pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.3, n_filts)\n",
    "    \n",
    "    low_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='low')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return low_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_high_pass(s, n_filts=10):\n",
    "    '''\n",
    "    Applies high pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.1, n_filts)\n",
    "    \n",
    "    high_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='high')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return high_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roll_stats(s, windows=[10, 50, 100, 500, 1000]):\n",
    "    '''\n",
    "    Calculates rolling stats like mean, std, min, max...\n",
    "    '''\n",
    "    roll_stats = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        roll_stats['roll_mean_' + str(w)] = s.rolling(window=w, min_periods=1).mean()\n",
    "        roll_stats['roll_std_' + str(w)] = s.rolling(window=w, min_periods=1).std()\n",
    "        roll_stats['roll_min_' + str(w)] = s.rolling(window=w, min_periods=1).min()\n",
    "        roll_stats['roll_max_' + str(w)] = s.rolling(window=w, min_periods=1).max()\n",
    "        roll_stats['roll_range_' + str(w)] = roll_stats['roll_max_' + str(w)] - roll_stats['roll_min_' + str(w)]\n",
    "        roll_stats['roll_q10_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.10)\n",
    "        roll_stats['roll_q25_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.25)\n",
    "        roll_stats['roll_q50_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.50)\n",
    "        roll_stats['roll_q75_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.75)\n",
    "        roll_stats['roll_q90_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.90)\n",
    "    \n",
    "    # add zeros when na values (std)\n",
    "    roll_stats = roll_stats.fillna(value=0)\n",
    "             \n",
    "    return roll_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ewm(s, windows=[10, 50, 100, 500, 1000]):\n",
    "    '''\n",
    "    Calculates exponential weighted functions\n",
    "    '''\n",
    "    ewm = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n",
    "        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n",
    "        \n",
    "    # add zeros when na values (std)\n",
    "    ewm = ewm.fillna(value=0)\n",
    "        \n",
    "    return ewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(s):\n",
    "    '''\n",
    "    All calculations together\n",
    "    '''\n",
    "    \n",
    "    gradients = calc_gradients(s)\n",
    "    low_pass = calc_low_pass(s)\n",
    "    high_pass = calc_high_pass(s)\n",
    "    roll_stats = calc_roll_stats(s)\n",
    "    ewm = calc_ewm(s)\n",
    "    \n",
    "    return pd.concat([s, gradients, low_pass, high_pass, roll_stats, ewm], axis=1)\n",
    "\n",
    "\n",
    "def divide_and_add_features(s, signal_size=500000):\n",
    "    '''\n",
    "    Divide the signal in bags of \"signal_size\".\n",
    "    Normalize the data dividing it by 15.0\n",
    "    '''\n",
    "    # normalize\n",
    "    s = s/15.0\n",
    "    \n",
    "    ls = []\n",
    "    for i in tqdm(range(int(s.shape[0]/signal_size))):\n",
    "        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n",
    "        sig_featured = add_features(sig)\n",
    "        ls.append(sig_featured)\n",
    "    \n",
    "    return pd.concat(ls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:28<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:34<00:00,  8.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# apply every feature to data\n",
    "df = divide_and_add_features(data['signal'])\n",
    "print('Reading data...')\n",
    "test = pd.read_csv('../input/test_clean.csv')\n",
    "print('Feature engineering...')\n",
    "test = divide_and_add_features(test['signal'])\n",
    "test_x = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the signals to see how they look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight= [  4.03176385   5.07168831   9.02650905   7.47821223  12.39433827\n",
      "  17.9935727   26.57990984  18.86685659  20.39293099  36.73229503\n",
      " 139.92667842]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'class_weight')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_class_weight(classes, exp=1):\n",
    "    '''\n",
    "    Weight of the class is inversely proportional to the population of the class.\n",
    "    There is an exponent for adding more weight.\n",
    "    '''\n",
    "    hist, _ = np.histogram(classes, bins=np.arange(12)-0.5)\n",
    "    class_weight = hist.sum()/np.power(hist, exp)\n",
    "    \n",
    "    return class_weight\n",
    "\n",
    "y_train = data['open_channels'].values\n",
    "\n",
    "class_weight = get_class_weight(y_train)\n",
    "print('class_weight=', class_weight)\n",
    "plt.figure()\n",
    "plt.title('classes')\n",
    "plt.hist(y_train, bins=np.arange(12)-0.5)\n",
    "plt.figure()\n",
    "plt.title('class_weight')\n",
    "plt.bar(np.arange(11), class_weight)\n",
    "plt.title('class_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mpl(shape):\n",
    "    '''\n",
    "    Returns a keras model\n",
    "    '''\n",
    "    \n",
    "    X_input = L.Input(shape)\n",
    "    \n",
    "    X = L.Dense(150, activation='relu')(X_input)\n",
    "    X = L.Dense(150, activation='relu')(X)\n",
    "    X = L.Dense(125, activation='relu')(X)\n",
    "    X = L.Dense(100, activation='relu')(X)\n",
    "    X = L.Dense(75, activation='relu')(X)\n",
    "    X = L.Dense(50, activation='relu')(X)\n",
    "    X = L.Dense(25, activation='relu')(X)\n",
    "    X = L.Dropout(0.25)(x)\n",
    "    X = L.normalization()(x)\n",
    "    X = L.Dense(11, activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'objective': 'regression',\n",
    "          'n_jobs': -1,\n",
    "          'seed': 236,\n",
    "          'num_leaves': 280,\n",
    "          'learning_rate': 0.026623466966581126,\n",
    "          'max_depth': 73,\n",
    "          'lambda_l1': 2.959759088169741,\n",
    "          'lambda_l2': 1.331172832164913,\n",
    "          'bagging_fraction': 0.9655406551472153,\n",
    "          'bagging_freq': 9,\n",
    "          'colsample_bytree': 0.6867118652742716}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "sep: (4000000, 105), (1000000, 105), (4000000,), (1000000,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c7e7ba2ab66d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     mlp.fit(x=X_train.values, y=y_train, epochs=MLP_EPOCH_NUM, batch_size=1024, class_weight=class_weight,\n\u001b[0;32m---> 31\u001b[0;31m            validation_data=(X_valid.values, y_valid), verbose=0)\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m#mlp.fit(x=X_train, y=y_train, epochs=MLP_EPOCH_NUM, batch_size=1024, class_weight=class_weight,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#       validation_data=(X_valid, y_valid), verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Keras-2.3.1-py3.7.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Keras-2.3.1-py3.7.egg/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                                          verbose=0)\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Keras-2.3.1-py3.7.egg/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits= 5 , shuffle=True, random_state=42)\n",
    "\n",
    "MLP_EPOCH_NUM = 80\n",
    "LGBM_BOOST_NUM = 3000\n",
    "\n",
    "\n",
    "\n",
    "preds = np.zeros(2000000*11).reshape((2000000, 11))\n",
    "oof_train = np.zeros((len(df),11))\n",
    "\n",
    "X = df#.values\n",
    "y = data['open_channels']\n",
    "y_values = data['open_channels'].values\n",
    "\n",
    "for i, (tdx, vdx) in enumerate(kf.split(X, y)):\n",
    "    print(f'Fold : {i}')\n",
    "    X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y_values[tdx], y_values[vdx]\n",
    "    #X_train, X_valid, y_train, y_valid = X[tdx], X[vdx], y_values[tdx], y_values[vdx]\n",
    "    print(f\"sep: {X_train.shape}, {X_valid.shape}, {y_train.shape}, {y_valid.shape}\")\n",
    "    \n",
    "    #MLP\n",
    "    mlp = create_mpl(X_train.values[0].shape)\n",
    "    #mlp = create_mpl(X_train[0].shape)\n",
    "    mlp.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    class_weight = get_class_weight(y_train)\n",
    "\n",
    "    mlp.fit(x=X_train.values, y=y_train, epochs=MLP_EPOCH_NUM, batch_size=1024, class_weight=class_weight,\n",
    "           validation_data=(X_valid.values, y_valid))\n",
    "    #mlp.fit(x=X_train, y=y_train, epochs=MLP_EPOCH_NUM, batch_size=1024, class_weight=class_weight,\n",
    "    #       validation_data=(X_valid, y_valid), verbose=0)\n",
    "    mlp_pred = mlp.predict(X_valid.values)\n",
    "    #mlp_pred = mlp.predict(X_valid)\n",
    "    f1_mlp = f1_score(y_valid, np.argmax(mlp_pred, axis=-1), average='macro')\n",
    "    print(f\"f1 score is :{f1_mlp}\")\n",
    "    plt.figure(1)\n",
    "    plt.plot(mlp.history.history['loss'], 'b', label='loss')\n",
    "    plt.plot(mlp.history.history['val_loss'], 'r', label='loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "    plt.figure(2)\n",
    "    plt.plot(mlp.history.history['sparse_categorical_accuracy'], 'g', label='sparse_categorical_accuracy')\n",
    "    plt.plot(mlp.history.history['val_sparse_categorical_accuracy'], 'r', label='val_sparse_categorical_accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # GBC\n",
    "    #lgb_dataset = lgb.Dataset(X_train, label=y_train, weight=class_weight[y_train])\n",
    "    lgb_dataset = lgb.Dataset(X_train.values, label=y_train, weight=class_weight[y_train])\n",
    "    #lgb_valid_dataset = lgb.Dataset(X_valid, label=y_valid, weight=class_weight[y_valid])\n",
    "    lgb_valid_dataset = lgb.Dataset(X_valid.values, label=y_valid, weight=class_weight[y_valid])\n",
    "    print('Training LGBM...')\n",
    "    gbc = lgb.train(lgb_r_params, lgb_dataset, LGBM_BOOST_NUM, valid_names=[\"train\", \"valid\"], \n",
    "                    valid_sets=[lgb_dataset, lgb_valid_dataset], verbose_eval=-1, \n",
    "                    feval=lgb_Metric, early_stopping_rounds=10)\n",
    "    print('LGBM trained!')\n",
    "    # predict on test\n",
    "    gbc_pred = gbc.predict(X_valid.values, num_iteration=gbc.best_iteration)\n",
    "    attr2 = {k: v for k, v in zip(df_columns, gbc.feature_importance()) if 200 > v and v>0}\n",
    "    print(\"weak fe##############\")\n",
    "    print(attr2)\n",
    "    print(\"##############\")\n",
    "    #gbc_pred = gbc.predict(X_valid, num_iteration=gbc.best_iteration)\n",
    "    print(f1_score(y_valid, np.argmax(gbc_pred, axis=1), average='macro'))\n",
    "    \n",
    "    # lists for keep results\n",
    "    f1s = []\n",
    "    alphas = []\n",
    "\n",
    "    # loop for every alpha\n",
    "    for alpha in tqdm(np.linspace(0,1,101)):\n",
    "        #y_pred = alpha*mlp_pred + (1 - alpha)*np.round(np.clip(gbc_pred, 0, 10)).astype(int)\n",
    "        y_pred = alpha*mlp_pred + (1 - alpha)*gbc_pred\n",
    "        f1 = f1_score(y_valid, np.argmax(y_pred, axis=1), average='macro')\n",
    "        f1s.append(f1)\n",
    "        alphas.append(alpha)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    f1s = np.array(f1s)\n",
    "    alphas = np.array(alphas)\n",
    "\n",
    "    # get best_alpha\n",
    "    best_alpha = alphas[np.argmax(f1s)]\n",
    "\n",
    "    print('best_f1=', f1s.max())\n",
    "    print('best_alpha=', best_alpha)\n",
    "    plt.plot(alphas, f1s)\n",
    "    plt.title('f1_score for ensemble')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('f1_score')\n",
    "    plt.show()\n",
    "    \n",
    "    mlp_pred = mlp.predict(X_valid.values)\n",
    "    gbc_pred = gbc.predict(X_valid.values, num_iteration=gbc.best_iteration)\n",
    "    pred = best_alpha*mlp_pred + (1 - best_alpha)*gbc_pred\n",
    "    \n",
    "    oof_train[vdx] = pred\n",
    "                           \n",
    "\n",
    "    mlp_pred = mlp.predict(test_x)\n",
    "    #mlp_pred = mlp.predict(test_df.values)\n",
    "    gbc_pred = gbc.predict(test_x, num_iteration=gbc.best_iteration)\n",
    "    #gbc_pred = gbc.predict(test_df.values, num_iteration=gbc.best_iteration)\n",
    "    pred = best_alpha*mlp_pred + (1 - best_alpha)*gbc_pred\n",
    "    preds += pred\n",
    "    \n",
    "    \n",
    "    print(f\"f1_mlp is {f1_mlp}\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
